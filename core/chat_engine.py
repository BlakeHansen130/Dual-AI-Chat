import os
import asyncio
import time
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from dotenv import load_dotenv

from config.constants import (
    MessageSender, MessagePurpose, DiscussionMode, ResponseHandlerType,
    COGNITO_SYSTEM_PROMPT, MUSE_SYSTEM_PROMPT, INITIAL_NOTEPAD_CONTENT,
    MAX_AUTO_RETRIES, RETRY_DELAY_BASE_MS, DISCUSSION_COMPLETE_TAG,
    DEFAULT_SHOW_THINKING_TO_USER, DEFAULT_SEND_THINKING_TO_AI
)
from config.models import ChatMessage, ParsedAIResponse, FailedStepPayload
from core.openai_service import OpenAIService
from core.response_parser import ResponseParser
from core.notepad_manager import NotepadManager
from ui.terminal_ui import TerminalUI

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class ChatEngine:
    """AIè¾©è®ºèŠå¤©å¼•æ“ - æ•´åˆæ‰€æœ‰æ¨¡å—å®ç°å®Œæ•´çš„è¾©è®ºæµç¨‹"""
    
    def __init__(self):
        """åˆå§‹åŒ–èŠå¤©å¼•æ“"""
        # åˆå§‹åŒ–æ ¸å¿ƒæœåŠ¡
        self.openai_service = OpenAIService()
        self.notepad_manager = NotepadManager()
        self.ui = TerminalUI()
        
        # è¯»å–é…ç½®
        self.model_name = os.getenv("DEFAULT_MODEL", "gpt-3.5-turbo")
        self.handler_type = ResponseHandlerType(os.getenv("RESPONSE_HANDLER_TYPE", "standard"))
        self.show_thinking_to_user = os.getenv("SHOW_THINKING_TO_USER", "true").lower() == "true"
        self.send_thinking_to_ai = os.getenv("SEND_THINKING_TO_AI", "false").lower() == "true"
        
        # è®¨è®ºé…ç½®
        self.discussion_mode = DiscussionMode.FIXED_TURNS  # å¯ä»¥åç»­æ”¹ä¸ºå¯é…ç½®
        self.max_turns = 3  # æ›´æ–°ä¸º3è½®ï¼Œæä¾›æ›´å……åˆ†çš„è¾©è®º
        
        # ä¼šè¯çŠ¶æ€
        self.messages: List[ChatMessage] = []
        self.discussion_log: List[str] = []
        self.current_turn = 0
        self.session_id = f"session_{int(time.time())}"
        self.session_start_time = datetime.now()  # æ·»åŠ ä¼šè¯å¼€å§‹æ—¶é—´
        self.thinking_records: List[Dict[str, Any]] = []  # è®°å½•æ€è€ƒè¿‡ç¨‹
        
        # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
        config_info = self.openai_service.get_current_config()
        self.ui.show_header(config_info)
    
    async def start_interactive_session(self):
        """å¯åŠ¨äº¤äº’å¼ä¼šè¯"""
        self.ui.show_welcome_animation()
        
        try:
            while True:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = self.ui.get_user_input()
                
                if not user_input.strip():
                    self.ui.show_system_message("è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜", "æç¤º")
                    continue
                
                # å¤„ç†ç”¨æˆ·è¾“å…¥
                await self.process_user_input(user_input)
                
                # æ˜¾ç¤ºä¼šè¯ç»Ÿè®¡
                self.ui.show_session_stats()
                
        except KeyboardInterrupt:
            self.ui.show_system_message("ç”¨æˆ·ç»ˆæ­¢ä¼šè¯", "ä¿¡æ¯")
        except Exception as e:
            self.ui.show_error(f"ä¼šè¯å‡ºç°å¼‚å¸¸: {str(e)}", "ä¸¥é‡é”™è¯¯")
        finally:
            self.ui.show_system_message("æ„Ÿè°¢ä½¿ç”¨ Dual AI Chatï¼", "å†è§")
    
    async def process_user_input(self, user_input: str) -> bool:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œæ‰§è¡Œå®Œæ•´çš„AIè¾©è®ºæµç¨‹
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
            
        Returns:
            bool: å¤„ç†æ˜¯å¦æˆåŠŸ
        """
        # é‡ç½®çŠ¶æ€
        self.discussion_log.clear()
        self.current_turn = 0
        
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        self.ui.show_user_message(user_input)
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        user_message = ChatMessage(
            id=self._generate_message_id(),
            text=user_input,
            sender=MessageSender.USER,
            purpose=MessagePurpose.USER_INPUT,
            timestamp=datetime.now()
        )
        self.messages.append(user_message)
        
        try:
            # ç¬¬ä¸€é˜¶æ®µï¼šCognitoåˆå§‹åˆ†æ
            cognito_initial_success = await self._cognito_initial_analysis(user_input)
            if not cognito_initial_success:
                return False
            
            # ç¬¬äºŒé˜¶æ®µï¼šAIè¾©è®ºå¾ªç¯
            discussion_success = await self._discussion_loop(user_input)
            if not discussion_success:
                return False
            
            # ç¬¬ä¸‰é˜¶æ®µï¼šCognitoæœ€ç»ˆç­”æ¡ˆ
            final_answer_success = await self._cognito_final_answer(user_input)
            if not final_answer_success:
                return False
            
            # æ˜¾ç¤ºè®¨è®ºç»“æŸ
            self.ui.show_discussion_end("AIè¾©è®ºå®Œæˆï¼Œå·²ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ")
            return True
            
        except Exception as e:
            self.ui.show_error(f"å¤„ç†ç”¨æˆ·è¾“å…¥æ—¶å‡ºé”™: {str(e)}", "å¤„ç†é”™è¯¯")
            return False
    
    async def _cognito_initial_analysis(self, user_input: str) -> bool:
        """Cognitoåˆå§‹åˆ†æé˜¶æ®µ"""
        self.ui.show_system_message("ğŸ§  Cognito å¼€å§‹åˆæ­¥åˆ†æ...")
        
        # æ„å»ºåˆå§‹åˆ†ææç¤º
        initial_prompt = f"""ç”¨æˆ·çš„æŸ¥è¯¢æ˜¯: "{user_input}"

è¯·é’ˆå¯¹æ­¤æŸ¥è¯¢æä¾›æ‚¨çš„åˆæ­¥æƒ³æ³•æˆ–åˆ†æï¼Œä»¥ä¾¿ {MessageSender.MUSE.value} (åˆ›æ„å‹AI) å¯ä»¥å›åº”å¹¶ä¸æ‚¨å¼€å§‹è®¨è®ºã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ã€‚"""
        
        # æ„å»ºåŒ…å«è®°äº‹æœ¬çš„ç³»ç»Ÿæç¤º
        system_prompt = self._build_prompt_with_notepad(COGNITO_SYSTEM_PROMPT)
        
        # æ‰§è¡ŒAIè°ƒç”¨
        parsed_response = await self._execute_ai_turn(
            sender=MessageSender.COGNITO,
            prompt=initial_prompt,
            system_prompt=system_prompt,
            purpose=MessagePurpose.COGNITO_TO_MUSE,
            step_identifier="cognito-initial-analysis"
        )
        
        if not parsed_response:
            return False
        
        # æ›´æ–°è®¨è®ºæ—¥å¿—
        self.discussion_log.append(f"{MessageSender.COGNITO.value}: {parsed_response.spoken_text}")
        
        return True
    
    async def _discussion_loop(self, user_input: str) -> bool:
        """AIè¾©è®ºå¾ªç¯"""
        previous_ai_signaled_stop = False
        
        for turn in range(self.max_turns):
            self.current_turn = turn + 1
            self.ui.show_discussion_progress(self.current_turn, self.max_turns, "fixed")
            
            # Museå›åº”Cognito
            muse_success = await self._muse_response_turn(user_input, previous_ai_signaled_stop)
            if not muse_success:
                return False
                
            # æ£€æŸ¥Museæ˜¯å¦å»ºè®®ç»“æŸè®¨è®º
            last_muse_response = self._get_last_parsed_response(MessageSender.MUSE)
            if last_muse_response and self.discussion_mode == DiscussionMode.AI_DRIVEN:
                if last_muse_response.discussion_should_end:
                    if previous_ai_signaled_stop:
                        self.ui.show_system_message("åŒæ–¹AIå·²åŒæ„ç»“æŸè®¨è®º")
                        break
                    previous_ai_signaled_stop = True
                    self.ui.show_system_message(f"{MessageSender.MUSE.value} å»ºè®®ç»“æŸè®¨è®ºï¼Œç­‰å¾… {MessageSender.COGNITO.value} å›åº”")
                else:
                    previous_ai_signaled_stop = False
            
            # å¦‚æœæ˜¯æœ€åä¸€è½®ï¼Œä¸éœ€è¦Cognitoå†å›åº”
            if turn >= self.max_turns - 1:
                break
                
            # Cognitoå›åº”Muse  
            cognito_success = await self._cognito_response_turn(user_input, previous_ai_signaled_stop)
            if not cognito_success:
                return False
                
            # æ£€æŸ¥Cognitoæ˜¯å¦å»ºè®®ç»“æŸè®¨è®º
            last_cognito_response = self._get_last_parsed_response(MessageSender.COGNITO)
            if last_cognito_response and self.discussion_mode == DiscussionMode.AI_DRIVEN:
                if last_cognito_response.discussion_should_end:
                    if previous_ai_signaled_stop:
                        self.ui.show_system_message("åŒæ–¹AIå·²åŒæ„ç»“æŸè®¨è®º")
                        break
                    previous_ai_signaled_stop = True
                    self.ui.show_system_message(f"{MessageSender.COGNITO.value} å»ºè®®ç»“æŸè®¨è®ºï¼Œç­‰å¾… {MessageSender.MUSE.value} å›åº”")
                else:
                    previous_ai_signaled_stop = False
        
        return True
    
    async def _muse_response_turn(self, user_input: str, previous_ai_signaled_stop: bool) -> bool:
        """Museå›åº”Cognitoçš„è½®æ¬¡"""
        self.ui.show_system_message(f"ğŸ­ {MessageSender.MUSE.value} æ­£åœ¨å›åº” {MessageSender.COGNITO.value}...")
        
        # è·å–æœ€åä¸€æ¡Cognitoæ¶ˆæ¯
        last_cognito_text = self._get_last_spoken_text(MessageSender.COGNITO)
        
        # æ„å»ºMuseçš„æç¤º
        muse_prompt = f"""ç”¨æˆ·çš„æŸ¥è¯¢æ˜¯: "{user_input}"

å½“å‰è®¨è®º (å‡ä¸ºä¸­æ–‡):
{chr(10).join(self.discussion_log)}

{MessageSender.COGNITO.value} (é€»è¾‘AI) åˆšåˆšè¯´: "{last_cognito_text}"

è¯·å›å¤ {MessageSender.COGNITO.value}ã€‚ç»§ç»­è®¨è®ºã€‚ä¿æŒæ‚¨çš„å›å¤ç®€æ´å¹¶ä½¿ç”¨ä¸­æ–‡ã€‚"""
        
        # å¦‚æœå‰ä¸€ä¸ªAIå»ºè®®ç»“æŸè®¨è®ºï¼Œæ·»åŠ ç›¸å…³æŒ‡ä»¤
        if previous_ai_signaled_stop:
            muse_prompt += f"\n\n{MessageSender.COGNITO.value} å·²åŒ…å« {DISCUSSION_COMPLETE_TAG} å»ºè®®ç»“æŸè®¨è®ºã€‚å¦‚æœæ‚¨åŒæ„ï¼Œè¯·åœ¨æ‚¨çš„å›å¤ä¸­ä¹ŸåŒ…å« {DISCUSSION_COMPLETE_TAG}ã€‚å¦åˆ™ï¼Œè¯·ç»§ç»­è®¨è®ºã€‚"
        
        # æ„å»ºç³»ç»Ÿæç¤º
        system_prompt = self._build_prompt_with_notepad(MUSE_SYSTEM_PROMPT)
        
        # æ‰§è¡ŒAIè°ƒç”¨
        parsed_response = await self._execute_ai_turn(
            sender=MessageSender.MUSE,
            prompt=muse_prompt,
            system_prompt=system_prompt,
            purpose=MessagePurpose.MUSE_TO_COGNITO,
            step_identifier=f"muse-response-turn-{self.current_turn}"
        )
        
        if not parsed_response:
            return False
        
        # æ›´æ–°è®¨è®ºæ—¥å¿—
        self.discussion_log.append(f"{MessageSender.MUSE.value}: {parsed_response.spoken_text}")
        
        return True
    
    async def _cognito_response_turn(self, user_input: str, previous_ai_signaled_stop: bool) -> bool:
        """Cognitoå›åº”Museçš„è½®æ¬¡"""
        self.ui.show_system_message(f"ğŸ§  {MessageSender.COGNITO.value} æ­£åœ¨å›åº” {MessageSender.MUSE.value}...")
        
        # è·å–æœ€åä¸€æ¡Museæ¶ˆæ¯
        last_muse_text = self._get_last_spoken_text(MessageSender.MUSE)
        
        # æ„å»ºCognitoçš„æç¤º
        cognito_prompt = f"""ç”¨æˆ·çš„æŸ¥è¯¢æ˜¯: "{user_input}"

å½“å‰è®¨è®º (å‡ä¸ºä¸­æ–‡):
{chr(10).join(self.discussion_log)}

{MessageSender.MUSE.value} (åˆ›æ„AI) åˆšåˆšè¯´: "{last_muse_text}"

è¯·å›å¤ {MessageSender.MUSE.value}ã€‚ç»§ç»­è®¨è®ºã€‚ä¿æŒæ‚¨çš„å›å¤ç®€æ´å¹¶ä½¿ç”¨ä¸­æ–‡ã€‚"""
        
        # å¦‚æœå‰ä¸€ä¸ªAIå»ºè®®ç»“æŸè®¨è®ºï¼Œæ·»åŠ ç›¸å…³æŒ‡ä»¤
        if previous_ai_signaled_stop:
            cognito_prompt += f"\n\n{MessageSender.MUSE.value} å·²åŒ…å« {DISCUSSION_COMPLETE_TAG} å»ºè®®ç»“æŸè®¨è®ºã€‚å¦‚æœæ‚¨åŒæ„ï¼Œè¯·åœ¨æ‚¨çš„å›å¤ä¸­ä¹ŸåŒ…å« {DISCUSSION_COMPLETE_TAG}ã€‚å¦åˆ™ï¼Œè¯·ç»§ç»­è®¨è®ºã€‚"
        
        # æ„å»ºç³»ç»Ÿæç¤º
        system_prompt = self._build_prompt_with_notepad(COGNITO_SYSTEM_PROMPT)
        
        # æ‰§è¡ŒAIè°ƒç”¨
        parsed_response = await self._execute_ai_turn(
            sender=MessageSender.COGNITO,
            prompt=cognito_prompt,
            system_prompt=system_prompt,
            purpose=MessagePurpose.COGNITO_TO_MUSE,
            step_identifier=f"cognito-response-turn-{self.current_turn}"
        )
        
        if not parsed_response:
            return False
        
        # æ›´æ–°è®¨è®ºæ—¥å¿—
        self.discussion_log.append(f"{MessageSender.COGNITO.value}: {parsed_response.spoken_text}")
        
        return True
    
    async def _cognito_final_answer(self, user_input: str) -> bool:
        """Cognitoæœ€ç»ˆç­”æ¡ˆé˜¶æ®µ"""
        self.ui.show_system_message("ğŸ§  Cognito æ­£åœ¨ç»¼åˆè®¨è®ºå†…å®¹ï¼Œå‡†å¤‡æœ€ç»ˆç­”æ¡ˆ...")
        
        # æ„å»ºæœ€ç»ˆç­”æ¡ˆæç¤º
        final_prompt = f"""ç”¨æˆ·æœ€åˆçš„æŸ¥è¯¢æ˜¯: "{user_input}"

æ‚¨ ({MessageSender.COGNITO.value}) å’Œ {MessageSender.MUSE.value} è¿›è¡Œäº†ä»¥ä¸‹è®¨è®º (å‡ä¸ºä¸­æ–‡):
{chr(10).join(self.discussion_log)}

åŸºäºæ•´ä¸ªäº¤æµè¿‡ç¨‹å’Œå…±äº«è®°äº‹æœ¬çš„æœ€ç»ˆçŠ¶æ€ï¼Œç»¼åˆæ‰€æœ‰å…³é”®ç‚¹ï¼Œå¹¶ä¸ºç”¨æˆ·åˆ¶å®šä¸€ä¸ªå…¨é¢ã€æœ‰ç”¨çš„æœ€ç»ˆç­”æ¡ˆã€‚

ç›´æ¥å›å¤ç”¨æˆ·ï¼Œè€Œä¸æ˜¯ {MessageSender.MUSE.value}ã€‚ç¡®ä¿ç­”æ¡ˆç»“æ„è‰¯å¥½ï¼Œæ˜“äºç†è§£ï¼Œå¹¶ä½¿ç”¨ä¸­æ–‡ã€‚å¦‚æœç›¸å…³ï¼Œæ‚¨å¯ä»¥åœ¨ç­”æ¡ˆä¸­å¼•ç”¨è®°äº‹æœ¬ã€‚å¦‚æœè®¤ä¸ºæœ‰å¿…è¦ï¼Œæ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨æ ‡å‡†çš„è®°äº‹æœ¬æ›´æ–°è¯´æ˜æœ€åä¸€æ¬¡æ›´æ–°è®°äº‹æœ¬ã€‚"""
        
        # æ„å»ºç³»ç»Ÿæç¤º
        system_prompt = self._build_prompt_with_notepad(COGNITO_SYSTEM_PROMPT)
        
        # æ‰§è¡ŒAIè°ƒç”¨
        parsed_response = await self._execute_ai_turn(
            sender=MessageSender.COGNITO,
            prompt=final_prompt,
            system_prompt=system_prompt,
            purpose=MessagePurpose.FINAL_RESPONSE,
            step_identifier="cognito-final-answer"
        )
        
        return parsed_response is not None
    
    async def _execute_ai_turn(
        self,
        sender: MessageSender,
        prompt: str,
        system_prompt: str,
        purpose: MessagePurpose,
        step_identifier: str
    ) -> Optional[ParsedAIResponse]:
        """
        æ‰§è¡Œå•ä¸ªAIå›åˆï¼ŒåŒ…å«é‡è¯•æœºåˆ¶
        
        Returns:
            ParsedAIResponse: è§£æåçš„AIå“åº”ï¼Œå¤±è´¥è¿”å›None
        """
        # æ˜¾ç¤ºæ€è€ƒåŠ¨ç”»
        target_ai = MessageSender.MUSE if sender == MessageSender.COGNITO else MessageSender.COGNITO
        if purpose != MessagePurpose.FINAL_RESPONSE:
            status = self.ui.show_ai_thinking(sender, target_ai)
        else:
            status = self.ui.show_ai_thinking(sender)
        
        try:
            # é‡è¯•å¾ªç¯
            for attempt in range(MAX_AUTO_RETRIES + 1):
                try:
                    # è°ƒç”¨API
                    api_response = self.openai_service.generate_response(
                        prompt=prompt,
                        model=self.model_name,
                        system_instruction=system_prompt,
                        handler_type=self.handler_type
                    )
                    
                    # æ£€æŸ¥APIé”™è¯¯
                    if api_response.error:
                        raise Exception(api_response.error)
                    
                    # è§£æå“åº”
                    parsed_response = ResponseParser.parse_ai_response(
                        raw_response=api_response.raw_response,
                        handler_type=self.handler_type,
                        model_name=self.model_name,
                        player_name=sender.value
                    )
                    
                    # åœæ­¢æ€è€ƒåŠ¨ç”»
                    status.stop()
                    
                    # æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœå¯ç”¨ä¸”å­˜åœ¨ï¼‰
                    if (self.show_thinking_to_user and 
                        parsed_response.thinking_content and 
                        parsed_response.thinking_content.strip()):
                        self.ui.show_thinking_process(sender, parsed_response.thinking_content)
                        
                        # è®°å½•æ€è€ƒè¿‡ç¨‹ç”¨äºå¯¼å‡º
                        self.thinking_records.append({
                            "sender": sender,
                            "thinking_content": parsed_response.thinking_content,
                            "timestamp": datetime.now(),
                            "purpose": purpose
                        })
                    
                    # æ˜¾ç¤ºAIæ¶ˆæ¯
                    self.ui.show_ai_message(
                        sender=sender,
                        message=parsed_response.spoken_text,
                        purpose=purpose,
                        duration_ms=api_response.duration_ms
                    )
                    
                    # å¤„ç†è®°äº‹æœ¬æ›´æ–°
                    if parsed_response.new_notepad_content:
                        self.notepad_manager.update_content(
                            parsed_response.new_notepad_content,
                            sender
                        )
                        self.ui.show_notepad_update(
                            parsed_response.new_notepad_content,
                            sender
                        )
                    
                    # æ·»åŠ æ¶ˆæ¯åˆ°å†å²
                    message = ChatMessage(
                        id=self._generate_message_id(),
                        text=parsed_response.spoken_text,
                        sender=sender,
                        purpose=purpose,
                        timestamp=datetime.now(),
                        duration_ms=api_response.duration_ms
                    )
                    self.messages.append(message)
                    
                    return parsed_response
                    
                except Exception as e:
                    if attempt < MAX_AUTO_RETRIES:
                        status.stop()
                        self.ui.show_system_message(
                            f"[{sender.value} {step_identifier}] è°ƒç”¨å¤±è´¥ï¼Œæ­£åœ¨é‡è¯• ({attempt + 1}/{MAX_AUTO_RETRIES})... {str(e)}",
                            "é‡è¯•"
                        )
                        await asyncio.sleep(RETRY_DELAY_BASE_MS * (attempt + 1) / 1000)
                        status = self.ui.show_ai_thinking(sender, target_ai if purpose != MessagePurpose.FINAL_RESPONSE else None)
                    else:
                        status.stop()
                        self.ui.show_error(
                            f"[{sender.value} {step_identifier}] åœ¨ {MAX_AUTO_RETRIES + 1} æ¬¡å°è¯•åå¤±è´¥: {str(e)}",
                            "APIè°ƒç”¨å¤±è´¥"
                        )
                        return None
            
        except Exception as e:
            status.stop()
            self.ui.show_error(f"æ‰§è¡ŒAIå›åˆæ—¶å‡ºç°å¼‚å¸¸: {str(e)}", "ä¸¥é‡é”™è¯¯")
            return None
    
    def _build_prompt_with_notepad(self, base_system_prompt: str) -> str:
        """æ„å»ºåŒ…å«è®°äº‹æœ¬å†…å®¹çš„ç³»ç»Ÿæç¤º"""
        current_notepad_content = self.notepad_manager.get_content()
        return base_system_prompt.replace("{notepad_content}", current_notepad_content)
    
    def _get_last_spoken_text(self, sender: MessageSender) -> str:
        """è·å–æŒ‡å®šå‘é€è€…çš„æœ€åä¸€æ¡spoken_text"""
        for message in reversed(self.messages):
            if message.sender == sender:
                return message.text
        return ""
    
    def _get_last_parsed_response(self, sender: MessageSender) -> Optional[ParsedAIResponse]:
        """è·å–æŒ‡å®šå‘é€è€…çš„æœ€åä¸€æ¡è§£æå“åº”ï¼ˆéœ€è¦ä»æ¶ˆæ¯å†å²é‡æ„ï¼‰"""
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…é¡¹ç›®ä¸­å¯èƒ½éœ€è¦ä¿å­˜ParsedAIResponseåˆ°å†å²
        # æš‚æ—¶è¿”å›Noneï¼Œå¦‚æœéœ€è¦å¯ä»¥æ‰©å±•
        return None
    
    def _generate_message_id(self) -> str:
        """ç”Ÿæˆå”¯ä¸€çš„æ¶ˆæ¯ID"""
        return f"{self.session_id}_{len(self.messages)}_{int(time.time() * 1000)}"
    
    def get_session_summary(self) -> Dict[str, Any]:
        """è·å–ä¼šè¯æ‘˜è¦"""
        return {
            "session_id": self.session_id,
            "total_messages": len(self.messages),
            "notepad_stats": self.notepad_manager.get_update_stats(),
            "current_notepad": self.notepad_manager.get_content(),
            "discussion_turns": self.current_turn,
            "model_used": self.model_name,
            "handler_type": self.handler_type.value
        }
    
    def reset_session(self):
        """é‡ç½®ä¼šè¯çŠ¶æ€"""
        self.messages.clear()
        self.discussion_log.clear()
        self.thinking_records.clear()
        self.notepad_manager.reset()
        self.current_turn = 0
        self.session_id = f"session_{int(time.time())}"
        self.session_start_time = datetime.now()
        self.ui.show_system_message("ä¼šè¯å·²é‡ç½®", "ä¿¡æ¯")
    
    def export_to_markdown(self, include_thinking: bool = True) -> str:
        """
        å¯¼å‡ºèŠå¤©è®°å½•ä¸ºMarkdownæ ¼å¼
        
        Args:
            include_thinking: æ˜¯å¦åŒ…å«æ€è€ƒè¿‡ç¨‹
            
        Returns:
            str: Markdownæ ¼å¼çš„èŠå¤©è®°å½•
        """
        md_content = []
        
        # æ ‡é¢˜å’Œä¼šè¯ä¿¡æ¯
        md_content.append("# ğŸ§ ğŸ­ Dual AI Chat ä¼šè¯è®°å½•")
        md_content.append("")
        
        # ä¼šè¯å…ƒä¿¡æ¯
        session_duration = datetime.now() - self.session_start_time
        session_stats = self.get_session_summary()
        
        md_content.append("## ğŸ“Š ä¼šè¯ä¿¡æ¯")
        md_content.append("")
        md_content.append(f"- **ä¼šè¯ID**: `{self.session_id}`")
        md_content.append(f"- **å¼€å§‹æ—¶é—´**: {self.session_start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        md_content.append(f"- **ç»“æŸæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        md_content.append(f"- **ä¼šè¯æ—¶é•¿**: {str(session_duration).split('.')[0]}")
        md_content.append(f"- **æ¶ˆæ¯æ€»æ•°**: {session_stats['total_messages']}")
        md_content.append(f"- **è®¨è®ºè½®æ•°**: {session_stats['discussion_turns']}")
        md_content.append(f"- **ä½¿ç”¨æ¨¡å‹**: {session_stats['model_used']}")
        md_content.append(f"- **å¤„ç†å™¨ç±»å‹**: {session_stats['handler_type']}")
        md_content.append("")
        
        # é…ç½®ä¿¡æ¯
        config = self.openai_service.get_current_config()
        md_content.append("## âš™ï¸ é…ç½®ä¿¡æ¯")
        md_content.append("")
        md_content.append(f"- **APIç«¯ç‚¹**: `{config['base_url']}`")
        md_content.append(f"- **æ¨¡å‹**: `{config['model']}`")
        md_content.append(f"- **å“åº”å¤„ç†å™¨**: `{config['handler_type']}`")
        md_content.append(f"- **æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹**: {self.show_thinking_to_user}")
        md_content.append(f"- **å‘é€æ€è€ƒç»™AI**: {self.send_thinking_to_ai}")
        md_content.append("")
        
        # å¯¹è¯å†…å®¹
        md_content.append("## ğŸ’¬ å¯¹è¯å†…å®¹")
        md_content.append("")
        
        # æŒ‰æ—¶é—´é¡ºåºå¤„ç†æ¶ˆæ¯å’Œæ€è€ƒè®°å½•
        all_records = []
        
        # æ·»åŠ æ¶ˆæ¯è®°å½•
        for msg in self.messages:
            all_records.append({
                "type": "message",
                "timestamp": msg.timestamp,
                "data": msg
            })
        
        # æ·»åŠ æ€è€ƒè®°å½•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if include_thinking:
            for thinking in self.thinking_records:
                all_records.append({
                    "type": "thinking",
                    "timestamp": thinking["timestamp"],
                    "data": thinking
                })
        
        # æŒ‰æ—¶é—´æ’åº
        all_records.sort(key=lambda x: x["timestamp"])
        
        # ç”Ÿæˆå†…å®¹
        for record in all_records:
            if record["type"] == "message":
                msg = record["data"]
                md_content.extend(self._format_message_for_export(msg))
            elif record["type"] == "thinking" and include_thinking:
                thinking = record["data"]
                md_content.extend(self._format_thinking_for_export(thinking))
        
        # æœ€ç»ˆè®°äº‹æœ¬çŠ¶æ€
        if self.notepad_manager.has_been_updated():
            md_content.append("## ğŸ“ æœ€ç»ˆè®°äº‹æœ¬çŠ¶æ€")
            md_content.append("")
            md_content.append("```markdown")
            md_content.append(self.notepad_manager.get_content())
            md_content.append("```")
            md_content.append("")
            
            # è®°äº‹æœ¬ç»Ÿè®¡
            notepad_stats = self.notepad_manager.get_update_stats()
            md_content.append("### è®°äº‹æœ¬ç»Ÿè®¡")
            md_content.append("")
            md_content.append(f"- **æ€»æ›´æ–°æ¬¡æ•°**: {notepad_stats['total_updates']}")
            md_content.append(f"- **Cognitoæ›´æ–°**: {notepad_stats['cognito_updates']} æ¬¡")
            md_content.append(f"- **Museæ›´æ–°**: {notepad_stats['muse_updates']} æ¬¡")
            md_content.append(f"- **æœ€åæ›´æ–°è€…**: {notepad_stats['last_updated_by']}")
            md_content.append(f"- **æœ€ç»ˆé•¿åº¦**: {notepad_stats['content_length']} å­—ç¬¦")
            md_content.append("")
        
        # è®¨è®ºæ‘˜è¦
        if self.discussion_log:
            md_content.append("## ğŸ”„ è®¨è®ºæ‘˜è¦")
            md_content.append("")
            for i, discussion_item in enumerate(self.discussion_log, 1):
                md_content.append(f"{i}. {discussion_item}")
            md_content.append("")
        
        # ç”Ÿæˆæ—¶é—´
        md_content.append("---")
        md_content.append("")
        md_content.append(f"*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")
        md_content.append(f"*ç”Ÿæˆå·¥å…·: Dual AI Chat v1.0*")
        
        return "\n".join(md_content)
    
    def _format_message_for_export(self, message: ChatMessage) -> List[str]:
        """æ ¼å¼åŒ–æ¶ˆæ¯ç”¨äºå¯¼å‡º"""
        content = []
        
        # æ¶ˆæ¯å¤´éƒ¨
        timestamp = message.timestamp.strftime('%H:%M:%S')
        
        if message.sender == MessageSender.USER:
            content.append(f"### ğŸ’¬ ç”¨æˆ·æé—® `{timestamp}`")
            content.append("")
            content.append(f"> {message.text}")
            
        elif message.sender == MessageSender.COGNITO:
            if message.purpose == MessagePurpose.FINAL_RESPONSE:
                title = "ğŸ§  Cognito æœ€ç»ˆç­”æ¡ˆ"
            elif message.purpose == MessagePurpose.COGNITO_TO_MUSE:
                title = "ğŸ§  Cognito â†’ Muse"
            else:
                title = "ğŸ§  Cognito"
                
            content.append(f"### {title} `{timestamp}`")
            if message.duration_ms:
                content.append(f"*è€—æ—¶: {message.duration_ms/1000:.1f}ç§’*")
            content.append("")
            content.append(message.text)
            
        elif message.sender == MessageSender.MUSE:
            content.append(f"### ğŸ­ Muse â†’ Cognito `{timestamp}`")
            if message.duration_ms:
                content.append(f"*è€—æ—¶: {message.duration_ms/1000:.1f}ç§’*")
            content.append("")
            content.append(message.text)
            
        elif message.sender == MessageSender.SYSTEM:
            content.append(f"### â„¹ï¸ ç³»ç»Ÿæ¶ˆæ¯ `{timestamp}`")
            content.append("")
            content.append(f"```")
            content.append(message.text)
            content.append(f"```")
        
        content.append("")
        return content
    
    def _format_thinking_for_export(self, thinking_record: Dict[str, Any]) -> List[str]:
        """æ ¼å¼åŒ–æ€è€ƒè¿‡ç¨‹ç”¨äºå¯¼å‡º"""
        content = []
        
        timestamp = thinking_record["timestamp"].strftime('%H:%M:%S')
        sender = thinking_record["sender"]
        
        if sender == MessageSender.COGNITO:
            emoji = "ğŸ’­ğŸ§ "
        else:
            emoji = "ğŸ’­ğŸ­"
            
        content.append(f"#### {emoji} {sender.value} æ€è€ƒè¿‡ç¨‹ `{timestamp}`")
        content.append("")
        content.append("<details>")
        content.append("<summary>ç‚¹å‡»å±•å¼€æ€è€ƒè¿‡ç¨‹</summary>")
        content.append("")
        content.append("```")
        content.append(thinking_record["thinking_content"])
        content.append("```")
        content.append("")
        content.append("</details>")
        content.append("")
        
        return content
    
    def save_markdown_export(self, filename: Optional[str] = None, include_thinking: bool = True) -> str:
        """
        ä¿å­˜èŠå¤©è®°å½•ä¸ºMarkdownæ–‡ä»¶
        
        Args:
            filename: æ–‡ä»¶åï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰
            include_thinking: æ˜¯å¦åŒ…å«æ€è€ƒè¿‡ç¨‹
            
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"dual_ai_chat_{timestamp}.md"
        
        # ç¡®ä¿æ–‡ä»¶åä»¥.mdç»“å°¾
        if not filename.endswith('.md'):
            filename += '.md'
        
        md_content = self.export_to_markdown(include_thinking)
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(md_content)
            return filename
        except Exception as e:
            raise Exception(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {str(e)}")